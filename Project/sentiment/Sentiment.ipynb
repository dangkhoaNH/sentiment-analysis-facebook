{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9N9xbH36xkJJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.20.0)\n",
      "Requirement already satisfied: pybrowsers in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.1)\n",
      "Requirement already satisfied: pywin32<304,>=303 in c:\\programdata\\anaconda3\\lib\\site-packages (from pybrowsers->webdriver-manager) (303)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vHFidh7nxtBy"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6tWeJ3hZxuGC"
   },
   "outputs": [],
   "source": [
    "#Create dictionary for posts and comments\n",
    "posts = dict()\n",
    "comments = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FiWA_nKQxvdD"
   },
   "outputs": [],
   "source": [
    "def initDriver():\n",
    "    WINDOW_SIZE = \"1920, 1080\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControllered\")\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")  # overcome limited resource problems\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_argument('disable-infobars')\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FM7OYPQnxxI-"
   },
   "outputs": [],
   "source": [
    "def convertToCookie(cookie):\n",
    "    try:\n",
    "        new_cookie = [\"c_user=\", \"xs=\"]\n",
    "        cookie_arr = cookie.split(\";\")\n",
    "        for i in cookie_arr:\n",
    "            if i.__contains__('c_user='):\n",
    "                new_cookie[0] = new_cookie[0] + (i.strip() + \";\").split(\"c_user=\")[1]\n",
    "            if i.__contains__('xs='):\n",
    "                new_cookie[1] = new_cookie[1] + (i.strip() + \";\").split(\"xs=\")[1]\n",
    "                if (len(new_cookie[1].split(\"|\"))):\n",
    "                    new_cookie[1] = new_cookie[1].split(\"|\")[0]\n",
    "                if (\";\" not in new_cookie[1]):\n",
    "                    new_cookie[1] = new_cookie[1] + \";\"\n",
    "\n",
    "        conv = new_cookie[0] + \" \" + new_cookie[1]\n",
    "        if (conv.split(\" \")[0] == \"c_user=\"):\n",
    "            return\n",
    "        else:\n",
    "            return conv\n",
    "    except:\n",
    "        print(\"Error Convert Cookie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YdXLD5Yyxyr9"
   },
   "outputs": [],
   "source": [
    "def loginFacebookByCookie(driver ,cookie):\n",
    "    try:\n",
    "        cookie = convertToCookie(cookie)\n",
    "        print(cookie)\n",
    "        if (cookie != None):\n",
    "            script = 'javascript:void(function(){ function setCookie(t) { var list = t.split(\"; \"); console.log(list); for (var i = list.length - 1; i >= 0; i--) { var cname = list[i].split(\"=\")[0]; var cvalue = list[i].split(\"=\")[1]; var d = new Date(); d.setTime(d.getTime() + (7*24*60*60*1000)); var expires = \";domain=.facebook.com;expires=\"+ d.toUTCString(); document.cookie = cname + \"=\" + cvalue + \"; \" + expires; } } function hex2a(hex) { var str = \"\"; for (var i = 0; i < hex.length; i += 2) { var v = parseInt(hex.substr(i, 2), 16); if (v) str += String.fromCharCode(v); } return str; } setCookie(\"' + cookie + '\"); location.href = \"https://mbasic.facebook.com\"; })();'\n",
    "            driver.execute_script(script)\n",
    "            sleep(5)\n",
    "    except:\n",
    "        print(\"Error login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "83aD8DMTx0S7"
   },
   "outputs": [],
   "source": [
    "def checkLiveClone(driver):\n",
    "    try:\n",
    "        driver.get(\"https://mbasic.facebook.com/\")\n",
    "        sleep(3)\n",
    "        driver.get(\"https://mbasic.facebook.com/\")\n",
    "        sleep(3)\n",
    "        elementLive = driver.find_elements(by=By.XPATH, value='//a[contains(@href, \"/messages/\")]')\n",
    "        if (len(elementLive) > 0):\n",
    "            print(\"Live\")\n",
    "            return True\n",
    "        return False\n",
    "    except:\n",
    "        print(\"Error Check Live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "F5qwxT1Vx1qH"
   },
   "outputs": [],
   "source": [
    "def loginFacebookByCookie(driver ,cookie):\n",
    "    try:\n",
    "        cookie = convertToCookie(cookie)\n",
    "        if (cookie != None):\n",
    "            script = 'javascript:void(function(){ function setCookie(t) { var list = t.split(\"; \"); console.log(list); for (var i = list.length - 1; i >= 0; i--) { var cname = list[i].split(\"=\")[0]; var cvalue = list[i].split(\"=\")[1]; var d = new Date(); d.setTime(d.getTime() + (7*24*60*60*1000)); var expires = \";domain=.facebook.com;expires=\"+ d.toUTCString(); document.cookie = cname + \"=\" + cvalue + \"; \" + expires; } } function hex2a(hex) { var str = \"\"; for (var i = 0; i < hex.length; i += 2) { var v = parseInt(hex.substr(i, 2), 16); if (v) str += String.fromCharCode(v); } return str; } setCookie(\"' + cookie + '\"); location.href = \"https://mbasic.facebook.com\"; })();'\n",
    "            driver.execute_script(script)\n",
    "            sleep(5)\n",
    "    except:\n",
    "        print(\"Error login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UKkrCvv0x3TZ"
   },
   "outputs": [],
   "source": [
    "def checkLiveCookie(driver, cookie):\n",
    "    try:\n",
    "        driver.get('https://mbasic.facebook.com/')\n",
    "        sleep(3)\n",
    "        driver.get('https://mbasic.facebook.com/')\n",
    "        sleep(3)\n",
    "        loginFacebookByCookie(driver ,cookie)\n",
    "\n",
    "        return checkLiveClone(driver)\n",
    "    except:\n",
    "        print(\"Error Check Live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RQdmiWMhx5Dd"
   },
   "outputs": [],
   "source": [
    "def getCommentByPost(driver, postId, target = 500):\n",
    "    try:\n",
    "        driver.get(posts[postId])\n",
    "        try:\n",
    "            commentTags = driver.find_elements(by=By.XPATH, value='//div[contains(@data-sigil, \"comment-body\")]')\n",
    "            if (len(commentTags) < target):\n",
    "                nextButton = driver.find_elements(by=By.XPATH, value='//*[contains(@id,\"see_next\")]/a')\n",
    "                if(len(nextButton)==1):\n",
    "                    nextButton[0].click()\n",
    "                    sleep(3)\n",
    "                repliesButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@href,\"comment/replies/?ctoken=\")]')\n",
    "                while (len(repliesButtons) > 0):\n",
    "                    for repliesButton in repliesButtons:\n",
    "                        repliesButton.click()\n",
    "                        sleep(3)\n",
    "                    repliesButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@href,\"comment/replies/?ctoken=\")]')\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "        commentTags = driver.find_elements(by=By.XPATH, value='//div[contains(@data-sigil, \"comment-body\")]')\n",
    "        if (len(commentTags)):\n",
    "            for comment in commentTags:\n",
    "                commentId = comment.get_attribute('data-commentid')\n",
    "                if(commentId and len(comments) < target):\n",
    "                    commentContent = comment.text\n",
    "                    innerLinks = comment.find_elements(by=By.TAG_NAME, value='a')\n",
    "                    if(len(innerLinks)):\n",
    "                        for innerLink in innerLinks:\n",
    "                            commentContent = commentContent.replace(innerLink.text, '')\n",
    "                    comments[commentId] = commentContent\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DX0rk1bLx52R"
   },
   "outputs": [],
   "source": [
    "def getPostsByFanpage(driver, pageId, amount):\n",
    "    driver.get(\"https://touch.facebook.com/\" + pageId)\n",
    "    while len(posts) < amount:\n",
    "        sleep(3)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        shareButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@href, \"/sharer.php\")]')\n",
    "        if (len(shareButtons)):\n",
    "            for shareButton  in shareButtons:\n",
    "                postId = shareButton.get_attribute('href').split('sid=')[1].split('&')[0]\n",
    "                commentButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@data-click, \"click_comment_ufi\") and contains(@data-click, \"'+str(postId)+'\")]')\n",
    "                if (len(commentButtons) == 1 and len(posts) < amount):\n",
    "                    posts[postId] = commentButtons[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s2ais30jx741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 16:17:04,936 INFO ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 103.0.5060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 16:17:04,939 INFO Current google-chrome version is 103.0.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 16:17:04,941 INFO Get LATEST chromedriver version for 103.0.5060 google-chrome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\Dang Khoa\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.53\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 16:17:05,149 INFO Driver [C:\\Users\\Dang Khoa\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.53\\chromedriver.exe] found in cache\n",
      "Live\n"
     ]
    }
   ],
   "source": [
    "cookie = \"c_user=100082982745987; xs=47%3A3rDjZrheBR82cA%3A2%3A1657434894%3A-1%3A-1;\"\n",
    "driver = initDriver()\n",
    "isLive = checkLiveCookie(driver, cookie)\n",
    "if (isLive):\n",
    "    getPostsByFanpage(driver, 'Theanh28/photos/a.1509486855763896/6306054136107120', 1)\n",
    "    for postId in posts:\n",
    "        getCommentByPost(driver, postId, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lmhh2J1eyD3z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bll2X3QFyE8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8K6HReI4yGU5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "113"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = comments.values()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tpkid59lyHqQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 16:19:20,905 INFO NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hôm nay All In T1, SGB kiếm tí vốn gập theo U1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1 chút 1 chút thôi:))))</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>Hi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>haha ơi chời à hog nhận ra thiệt lun á</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>chúa hè rứ thôi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>tau</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>113 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment\n",
       "0                                                  NaN\n",
       "1    Công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...\n",
       "2     đệm vào chả vậy , ngực như cái chén lót thêm ...\n",
       "3    khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...\n",
       "4    Hôm nay All In T1, SGB kiếm tí vốn gập theo U1...\n",
       "..                                                 ...\n",
       "108                            1 chút 1 chút thôi:))))\n",
       "109                                                 Hi\n",
       "110             haha ơi chời à hog nhận ra thiệt lun á\n",
       "111                                    chúa hè rứ thôi\n",
       "112                                                tau\n",
       "\n",
       "[113 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "df = pd.DataFrame(data, columns=['comment'])\n",
    "df.to_csv('comments-predict.csv')\n",
    "df = pd.read_csv('comments-predict.csv')\n",
    "# Delete index column\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\programdata\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: underthesea in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (8.0.4)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (3.7)\n",
      "Requirement already satisfied: underthesea-core==0.0.4_alpha.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (0.0.4a10)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (2.27.1)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (1.1.0)\n",
      "Requirement already satisfied: unidecode in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (4.64.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (1.0.2)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->underthesea) (2022.3.15)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (3.3)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->underthesea) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->underthesea) (2.2.0)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->underthesea) (1.21.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import emoji\n",
    "import string\n",
    "from underthesea import word_tokenize\n",
    "from underthesea import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dang Khoa\\AppData\\Local\\Temp\\ipykernel_5456\\1010956789.py:15: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  return emoji.get_emoji_regexp().sub(\"\", text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "      <td>công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "      <td>đệm chả ngực chén lót vải vd bát úp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...</td>\n",
       "      <td>diện đồ nhếch nhác phèn ịa diện đồ phèn ịa y ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hôm nay all in t1, sgb kiếm tí vốn gập theo u1...</td>\n",
       "      <td>hôm nay all in t sgb kiếm tí vốn gập u việt n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diện áo đẹp chất lượng nè &lt;3  #1xxk &lt;3</td>\n",
       "      <td>diện áo đẹp chất lượng nè xxk</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>em á</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>sương sương thôi?</td>\n",
       "      <td>sương sương</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1 chút 1 chút thôi:))))</td>\n",
       "      <td>chút chút</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>haha ơi chời à hog nhận ra thiệt lun á</td>\n",
       "      <td>haha chời hog thiệt lun</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>chúa hè rứ thôi</td>\n",
       "      <td>chúa hè rứ</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "1    công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...   \n",
       "2     đệm vào chả vậy , ngực như cái chén lót thêm ...   \n",
       "3    khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...   \n",
       "4    hôm nay all in t1, sgb kiếm tí vốn gập theo u1...   \n",
       "5               diện áo đẹp chất lượng nè <3  #1xxk <3   \n",
       "..                                                 ...   \n",
       "106                                              em á    \n",
       "107                                  sương sương thôi?   \n",
       "108                            1 chút 1 chút thôi:))))   \n",
       "110             haha ơi chời à hog nhận ra thiệt lun á   \n",
       "111                                    chúa hè rứ thôi   \n",
       "\n",
       "                                               segment  \n",
       "1     công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...  \n",
       "2                 đệm chả ngực chén lót vải vd bát úp   \n",
       "3     diện đồ nhếch nhác phèn ịa diện đồ phèn ịa y ...  \n",
       "4     hôm nay all in t sgb kiếm tí vốn gập u việt n...  \n",
       "5                       diện áo đẹp chất lượng nè xxk   \n",
       "..                                                 ...  \n",
       "106                                                     \n",
       "107                                       sương sương   \n",
       "108                                         chút chút   \n",
       "110                           haha chời hog thiệt lun   \n",
       "111                                        chúa hè rứ   \n",
       "\n",
       "[85 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process data crawl before model\n",
    "\n",
    "# Basic preprocessing as lower string\n",
    "def pre_processing(text):\n",
    "    return text.str.lower()\n",
    "\n",
    "df['comment'] = pre_processing(df['comment'])\n",
    "\n",
    "# Delete NaN and empty row\n",
    "df = df[df.comment != '']\n",
    "df = df.dropna(subset=['comment'])\n",
    "df = df[df['comment'].apply(lambda comment: len(str(comment)) >= 5)]\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(\"\", text)\n",
    "\n",
    "df['comment'] = df['comment'].map(lambda comment: remove_emoji(comment))\n",
    "\n",
    "df['comment'] = df['comment'].map(lambda comment: comment.replace(string.punctuation,''))\n",
    "df['comment'] = df['comment'].map(lambda comment: comment.replace('_',' '))\n",
    "\n",
    "# Word segmentation\n",
    "df['segment'] = df['comment'].map(lambda comment: word_tokenize(comment))\n",
    "\n",
    "# Remove vietnamese stopwords - https://github.com/stopwords/vietnamese-stopwords\n",
    "\n",
    "# Read vietnamese stopwords file\n",
    "stopwords_df = pd.read_table('vietnamese-stopwords.txt')\n",
    "stopwords = stopwords_df.values.flatten()\n",
    "\n",
    "# Remove vietnamese stopwords function\n",
    "def remove_stopwords(segments):\n",
    "    return [item for item in segments if item not in stopwords]\n",
    "\n",
    "df['segment'] = df['segment'].map(lambda segments: remove_stopwords(segments))\n",
    "\n",
    "def process(text):\n",
    "    text = re.sub('&lt;/?.*?&gt;', ' &lt;&gt; ', str(text))\n",
    "    text = re.sub('(\\\\d|\\\\W)+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df['segment'] = df['segment'].apply(lambda x: process(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...</td>\n",
       "      <td>['hôm nay', 'đi', 'châu đốc', 'ghé', 'quán', '...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đây hẳn hoi là sưởng bánh bao nên mua gần như ...</td>\n",
       "      <td>['hẳn hoi', 'sưởng', 'bánh bao', 'mua', 'giá b...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>không gian sang choảnh mà giá k hề sang tí nào...</td>\n",
       "      <td>['không gian', 'choảnh', 'giá', 'k', 'hề', 'tí...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhưng người ta xinh hơn c :))))</td>\n",
       "      <td>['người ta', 'xinh', 'c', ':))))']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...</td>\n",
       "      <td>['xem xét', 'kỹ', 'đi', 'mấy', 'thằng', 'đb']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109824</th>\n",
       "      <td>ý nghĩ tiêu cực.</td>\n",
       "      <td>['ý nghĩ', 'tiêu cực', '.']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109825</th>\n",
       "      <td>chết cụ lũ súc sinh chúng m</td>\n",
       "      <td>['chết', 'cụ', 'lũ', 'súc sinh', 'm']</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109826</th>\n",
       "      <td>thôi ông anh ơi, người bình thường chứ có phả...</td>\n",
       "      <td>[',', 'bình thường', 'thần thánh', 'đ', 'đòi',...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109827</th>\n",
       "      <td>tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...</td>\n",
       "      <td>['mạnh mẽ', '.', 'chúng em', 'đằng', 'sauuu', ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109828</th>\n",
       "      <td>thầy bán cho nó đúng k</td>\n",
       "      <td>['thầy', 'k']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  \\\n",
       "0       hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...   \n",
       "1       đây hẳn hoi là sưởng bánh bao nên mua gần như ...   \n",
       "2       không gian sang choảnh mà giá k hề sang tí nào...   \n",
       "3                         nhưng người ta xinh hơn c :))))   \n",
       "4       hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...   \n",
       "...                                                   ...   \n",
       "109824                                   ý nghĩ tiêu cực.   \n",
       "109825                        chết cụ lũ súc sinh chúng m   \n",
       "109826   thôi ông anh ơi, người bình thường chứ có phả...   \n",
       "109827  tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...   \n",
       "109828                             thầy bán cho nó đúng k   \n",
       "\n",
       "                                                  segment emotion  \n",
       "0       ['hôm nay', 'đi', 'châu đốc', 'ghé', 'quán', '...     neg  \n",
       "1       ['hẳn hoi', 'sưởng', 'bánh bao', 'mua', 'giá b...     pos  \n",
       "2       ['không gian', 'choảnh', 'giá', 'k', 'hề', 'tí...     pos  \n",
       "3                      ['người ta', 'xinh', 'c', ':))))']     neu  \n",
       "4           ['xem xét', 'kỹ', 'đi', 'mấy', 'thằng', 'đb']     neu  \n",
       "...                                                   ...     ...  \n",
       "109824                        ['ý nghĩ', 'tiêu cực', '.']     neu  \n",
       "109825              ['chết', 'cụ', 'lũ', 'súc sinh', 'm']     neg  \n",
       "109826  [',', 'bình thường', 'thần thánh', 'đ', 'đòi',...     neu  \n",
       "109827  ['mạnh mẽ', '.', 'chúng em', 'đằng', 'sauuu', ...     pos  \n",
       "109828                                      ['thầy', 'k']     neu  \n",
       "\n",
       "[109829 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"comments.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...</td>\n",
       "      <td>hôm nay đi châu đốc ghé quán hủ tiếu bình thư...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đây hẳn hoi là sưởng bánh bao nên mua gần như ...</td>\n",
       "      <td>hẳn hoi sưởng bánh bao mua giá buôn bánh hàng...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>không gian sang choảnh mà giá k hề sang tí nào...</td>\n",
       "      <td>không gian choảnh giá k hề tí hợp vs mấy hẹn ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhưng người ta xinh hơn c :))))</td>\n",
       "      <td>người ta xinh c</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...</td>\n",
       "      <td>xem xét kỹ đi mấy thằng đb</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109824</th>\n",
       "      <td>ý nghĩ tiêu cực.</td>\n",
       "      <td>ý nghĩ tiêu cực</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109825</th>\n",
       "      <td>chết cụ lũ súc sinh chúng m</td>\n",
       "      <td>chết cụ lũ súc sinh m</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109826</th>\n",
       "      <td>thôi ông anh ơi, người bình thường chứ có phả...</td>\n",
       "      <td>bình thường thần thánh đ đòi học câu thi học ...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109827</th>\n",
       "      <td>tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...</td>\n",
       "      <td>mạnh mẽ chúng em đằng sauuu i love sơn tùng m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109828</th>\n",
       "      <td>thầy bán cho nó đúng k</td>\n",
       "      <td>thầy k</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  \\\n",
       "0       hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...   \n",
       "1       đây hẳn hoi là sưởng bánh bao nên mua gần như ...   \n",
       "2       không gian sang choảnh mà giá k hề sang tí nào...   \n",
       "3                         nhưng người ta xinh hơn c :))))   \n",
       "4       hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...   \n",
       "...                                                   ...   \n",
       "109824                                   ý nghĩ tiêu cực.   \n",
       "109825                        chết cụ lũ súc sinh chúng m   \n",
       "109826   thôi ông anh ơi, người bình thường chứ có phả...   \n",
       "109827  tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...   \n",
       "109828                             thầy bán cho nó đúng k   \n",
       "\n",
       "                                                  segment emotion  \n",
       "0        hôm nay đi châu đốc ghé quán hủ tiếu bình thư...     neg  \n",
       "1        hẳn hoi sưởng bánh bao mua giá buôn bánh hàng...     pos  \n",
       "2        không gian choảnh giá k hề tí hợp vs mấy hẹn ...     pos  \n",
       "3                                        người ta xinh c      neu  \n",
       "4                             xem xét kỹ đi mấy thằng đb      neu  \n",
       "...                                                   ...     ...  \n",
       "109824                                   ý nghĩ tiêu cực      neu  \n",
       "109825                             chết cụ lũ súc sinh m      neg  \n",
       "109826   bình thường thần thánh đ đòi học câu thi học ...     neu  \n",
       "109827   mạnh mẽ chúng em đằng sauuu i love sơn tùng m...     pos  \n",
       "109828                                            thầy k      neu  \n",
       "\n",
       "[109829 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['segment'] = data['segment'].apply(lambda x: process(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = data['segment']\n",
    "emotion = data['emotion']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    binary=True, ngram_range=(1, 2),\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save vectorizer\n",
    "vectorizer_file = 'vectorizer_file.sav'\n",
    "joblib.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "# Load vectorizer\n",
    "loaded_vectorizer_file = joblib.load('vectorizer_file.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87863, 700968) (87863,)\n",
      "(21966, 700968) (21966,)\n"
     ]
    }
   ],
   "source": [
    "#data test and data train \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, emotion, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model LinearSVC\n",
    "linear = LinearSVC(C=1, max_iter=1000)\n",
    "linear = linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_model.sav']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearModel = 'linear_model.sav'\n",
    "joblib.dump(linear, linearModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_linearModel = joblib.load('linear_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.70      0.73      8084\n",
      "         neu       0.70      0.82      0.75      7381\n",
      "         pos       0.80      0.71      0.75      6501\n",
      "\n",
      "    accuracy                           0.74     21966\n",
      "   macro avg       0.75      0.74      0.74     21966\n",
      "weighted avg       0.75      0.74      0.74     21966\n",
      "\n",
      "Accuracy score : 0.7431485022307202\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "y_pred = loaded_linearModel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score :\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'neu' 'neg' 'neu' 'pos' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neu'\n",
      " 'neg' 'pos' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neg' 'neg' 'neg' 'neu'\n",
      " 'neu' 'pos' 'neu' 'neu' 'pos' 'neg' 'neg' 'pos' 'neu' 'neg' 'neu' 'neu'\n",
      " 'neg' 'neu' 'neg' 'neu' 'neg' 'neu' 'neu' 'neg' 'neu' 'neu' 'pos' 'neg'\n",
      " 'neu' 'neu' 'pos' 'neu' 'neg' 'neu' 'neu' 'pos' 'neu' 'neu' 'neu' 'neg'\n",
      " 'neu' 'neg' 'neu' 'neg' 'neu' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neu'\n",
      " 'neu' 'neu' 'pos' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neu' 'neu'\n",
      " 'neg']\n"
     ]
    }
   ],
   "source": [
    "output = loaded_linearModel.predict(loaded_vectorizer_file.transform(df['segment']))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "      <td>công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "      <td>đệm chả ngực chén lót vải vd bát úp</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...</td>\n",
       "      <td>diện đồ nhếch nhác phèn ịa diện đồ phèn ịa y ...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hôm nay all in t1, sgb kiếm tí vốn gập theo u1...</td>\n",
       "      <td>hôm nay all in t sgb kiếm tí vốn gập u việt n...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diện áo đẹp chất lượng nè &lt;3  #1xxk &lt;3</td>\n",
       "      <td>diện áo đẹp chất lượng nè xxk</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>em á</td>\n",
       "      <td></td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>sương sương thôi?</td>\n",
       "      <td>sương sương</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1 chút 1 chút thôi:))))</td>\n",
       "      <td>chút chút</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>haha ơi chời à hog nhận ra thiệt lun á</td>\n",
       "      <td>haha chời hog thiệt lun</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>chúa hè rứ thôi</td>\n",
       "      <td>chúa hè rứ</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "1    công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...   \n",
       "2     đệm vào chả vậy , ngực như cái chén lót thêm ...   \n",
       "3    khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...   \n",
       "4    hôm nay all in t1, sgb kiếm tí vốn gập theo u1...   \n",
       "5               diện áo đẹp chất lượng nè <3  #1xxk <3   \n",
       "..                                                 ...   \n",
       "106                                              em á    \n",
       "107                                  sương sương thôi?   \n",
       "108                            1 chút 1 chút thôi:))))   \n",
       "110             haha ơi chời à hog nhận ra thiệt lun á   \n",
       "111                                    chúa hè rứ thôi   \n",
       "\n",
       "                                               segment emotion  \n",
       "1     công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...     pos  \n",
       "2                 đệm chả ngực chén lót vải vd bát úp      neu  \n",
       "3     diện đồ nhếch nhác phèn ịa diện đồ phèn ịa y ...     neg  \n",
       "4     hôm nay all in t sgb kiếm tí vốn gập u việt n...     neu  \n",
       "5                       diện áo đẹp chất lượng nè xxk      pos  \n",
       "..                                                 ...     ...  \n",
       "106                                                        neu  \n",
       "107                                       sương sương      neg  \n",
       "108                                         chút chút      neu  \n",
       "110                           haha chời hog thiệt lun      neu  \n",
       "111                                        chúa hè rứ      neg  \n",
       "\n",
       "[85 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(2, \"emotion\", output)\n",
    "# df.drop(\"emotion\", axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogisticRegression model\n",
    "Logistic = LogisticRegression(max_iter=1000)\n",
    "Logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_model.sav']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticModel = 'logistic_model.sav'\n",
    "joblib.dump(Logistic, logisticModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_logisticModel = joblib.load('logistic_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LogisticRegression: 0.7473367932258945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.70      0.73      8084\n",
      "         neu       0.69      0.85      0.76      7381\n",
      "         pos       0.82      0.69      0.75      6501\n",
      "\n",
      "    accuracy                           0.75     21966\n",
      "   macro avg       0.76      0.75      0.75     21966\n",
      "weighted avg       0.76      0.75      0.75     21966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_logisticModel.predict(X_test)\n",
    "print(\"Accuracy LogisticRegression:\", accuracy_score(y_test,y_pred ))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'neu' 'neg' 'neu' 'pos' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neu'\n",
      " 'neg' 'pos' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neg' 'neg' 'neg' 'neg'\n",
      " 'neu' 'pos' 'neu' 'neu' 'pos' 'neg' 'neg' 'pos' 'neu' 'neg' 'neu' 'neu'\n",
      " 'neg' 'neu' 'neg' 'neu' 'neg' 'neu' 'neu' 'neg' 'neu' 'neu' 'pos' 'neg'\n",
      " 'neu' 'neu' 'pos' 'neu' 'neg' 'neu' 'neu' 'pos' 'neu' 'neu' 'neu' 'neg'\n",
      " 'neu' 'neu' 'neu' 'neg' 'neu' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg'\n",
      " 'neu' 'neu' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neu' 'pos'\n",
      " 'neu']\n"
     ]
    }
   ],
   "source": [
    "outputLogistic = loaded_logisticModel.predict(loaded_vectorizer_file.transform(df['segment']))\n",
    "print(outputLogistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotionLogistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "      <td>công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "      <td>đệm chả ngực chén lót vải vd bát úp</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...</td>\n",
       "      <td>diện đồ nhếch nhác phèn ịa diện đồ phèn ịa y ...</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hôm nay all in t1, sgb kiếm tí vốn gập theo u1...</td>\n",
       "      <td>hôm nay all in t sgb kiếm tí vốn gập u việt n...</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>diện áo đẹp chất lượng nè &lt;3  #1xxk &lt;3</td>\n",
       "      <td>diện áo đẹp chất lượng nè xxk</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>em á</td>\n",
       "      <td></td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>sương sương thôi?</td>\n",
       "      <td>sương sương</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1 chút 1 chút thôi:))))</td>\n",
       "      <td>chút chút</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>haha ơi chời à hog nhận ra thiệt lun á</td>\n",
       "      <td>haha chời hog thiệt lun</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>chúa hè rứ thôi</td>\n",
       "      <td>chúa hè rứ</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "1    công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...   \n",
       "2     đệm vào chả vậy , ngực như cái chén lót thêm ...   \n",
       "3    khi chưa diện đồ thì nhếch nhác, phèn ịa .. nh...   \n",
       "4    hôm nay all in t1, sgb kiếm tí vốn gập theo u1...   \n",
       "5               diện áo đẹp chất lượng nè <3  #1xxk <3   \n",
       "..                                                 ...   \n",
       "106                                              em á    \n",
       "107                                  sương sương thôi?   \n",
       "108                            1 chút 1 chút thôi:))))   \n",
       "110             haha ơi chời à hog nhận ra thiệt lun á   \n",
       "111                                    chúa hè rứ thôi   \n",
       "\n",
       "                                               segment emotion emotionLogistic  \n",
       "1     công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...     pos             pos  \n",
       "2                 đệm chả ngực chén lót vải vd bát úp      neu             neu  \n",
       "3     diện đồ nhếch nhác phèn ịa diện đồ phèn ịa y ...     neg             neg  \n",
       "4     hôm nay all in t sgb kiếm tí vốn gập u việt n...     neu             neu  \n",
       "5                       diện áo đẹp chất lượng nè xxk      pos             pos  \n",
       "..                                                 ...     ...             ...  \n",
       "106                                                        neu             neu  \n",
       "107                                       sương sương      neg             neg  \n",
       "108                                         chút chút      neu             neu  \n",
       "110                           haha chời hog thiệt lun      neu             neu  \n",
       "111                                        chúa hè rứ      neg             neg  \n",
       "\n",
       "[85 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(3, \"emotionLogistic\", output)\n",
    "# df.drop(\"emotion\", axis=1, inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
