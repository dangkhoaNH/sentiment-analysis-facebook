{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9N9xbH36xkJJ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: selenium in c:\\programdata\\anaconda3\\lib\\site-packages (4.3.0)\n",
      "Requirement already satisfied: urllib3[secure,socks]~=1.26 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (1.26.9)\n",
      "Requirement already satisfied: trio~=0.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.21.0)\n",
      "Requirement already satisfied: trio-websocket~=0.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from selenium) (0.9.2)\n",
      "Requirement already satisfied: cffi>=1.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.15.0)\n",
      "Requirement already satisfied: idna in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (3.3)\n",
      "Requirement already satisfied: attrs>=19.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (21.4.0)\n",
      "Requirement already satisfied: async-generator>=1.9 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.10)\n",
      "Requirement already satisfied: sortedcontainers in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (2.4.0)\n",
      "Requirement already satisfied: outcome in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: sniffio in c:\\programdata\\anaconda3\\lib\\site-packages (from trio~=0.17->selenium) (1.2.0)\n",
      "Requirement already satisfied: pycparser in c:\\programdata\\anaconda3\\lib\\site-packages (from cffi>=1.14->trio~=0.17->selenium) (2.21)\n",
      "Requirement already satisfied: wsproto>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from trio-websocket~=0.9->selenium) (1.1.0)\n",
      "Requirement already satisfied: PySocks!=1.5.7,<2.0,>=1.5.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (1.7.1)\n",
      "Requirement already satisfied: certifi in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (2021.10.8)\n",
      "Requirement already satisfied: pyOpenSSL>=0.14 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (21.0.0)\n",
      "Requirement already satisfied: cryptography>=1.3.4 in c:\\programdata\\anaconda3\\lib\\site-packages (from urllib3[secure,socks]~=1.26->selenium) (3.4.8)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from pyOpenSSL>=0.14->urllib3[secure,socks]~=1.26->selenium) (1.16.0)\n",
      "Requirement already satisfied: h11<1,>=0.9.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from wsproto>=0.14->trio-websocket~=0.9->selenium) (0.13.0)\n",
      "Requirement already satisfied: webdriver-manager in c:\\programdata\\anaconda3\\lib\\site-packages (3.8.0)\n",
      "Requirement already satisfied: pybrowsers in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.4.1)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (2.27.1)\n",
      "Requirement already satisfied: python-dotenv in c:\\programdata\\anaconda3\\lib\\site-packages (from webdriver-manager) (0.20.0)\n",
      "Requirement already satisfied: pywin32<304,>=303 in c:\\programdata\\anaconda3\\lib\\site-packages (from pybrowsers->webdriver-manager) (303)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (1.26.9)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2021.10.8)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->webdriver-manager) (3.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install selenium\n",
    "!pip install webdriver-manager"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "vHFidh7nxtBy"
   },
   "outputs": [],
   "source": [
    "from time import sleep\n",
    "\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "6tWeJ3hZxuGC"
   },
   "outputs": [],
   "source": [
    "#Create dictionary for posts and comments\n",
    "posts = dict()\n",
    "comments = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "FiWA_nKQxvdD"
   },
   "outputs": [],
   "source": [
    "def initDriver():\n",
    "    WINDOW_SIZE = \"1920, 1080\"\n",
    "    chrome_options = Options()\n",
    "    chrome_options.add_argument(\"--window-size=%s\" % WINDOW_SIZE)\n",
    "    chrome_options.add_argument('--no-sandbox')\n",
    "    chrome_options.add_argument(\"--disable-blink-features=AutomationControllered\")\n",
    "    chrome_options.add_experimental_option('useAutomationExtension', False)\n",
    "    prefs = {\"profile.default_content_setting_values.notifications\": 2}\n",
    "    chrome_options.add_experimental_option(\"prefs\", prefs)\n",
    "    chrome_options.add_argument(\"--disable-dev-shm-usage\")  # overcome limited resource problems\n",
    "    chrome_options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "    chrome_options.add_argument('disable-infobars')\n",
    "    driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=chrome_options)\n",
    "    return driver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "FM7OYPQnxxI-"
   },
   "outputs": [],
   "source": [
    "def convertToCookie(cookie):\n",
    "    try:\n",
    "        new_cookie = [\"c_user=\", \"xs=\"]\n",
    "        cookie_arr = cookie.split(\";\")\n",
    "        for i in cookie_arr:\n",
    "            if i.__contains__('c_user='):\n",
    "                new_cookie[0] = new_cookie[0] + (i.strip() + \";\").split(\"c_user=\")[1]\n",
    "            if i.__contains__('xs='):\n",
    "                new_cookie[1] = new_cookie[1] + (i.strip() + \";\").split(\"xs=\")[1]\n",
    "                if (len(new_cookie[1].split(\"|\"))):\n",
    "                    new_cookie[1] = new_cookie[1].split(\"|\")[0]\n",
    "                if (\";\" not in new_cookie[1]):\n",
    "                    new_cookie[1] = new_cookie[1] + \";\"\n",
    "\n",
    "        conv = new_cookie[0] + \" \" + new_cookie[1]\n",
    "        if (conv.split(\" \")[0] == \"c_user=\"):\n",
    "            return\n",
    "        else:\n",
    "            return conv\n",
    "    except:\n",
    "        print(\"Error Convert Cookie\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "YdXLD5Yyxyr9"
   },
   "outputs": [],
   "source": [
    "def loginFacebookByCookie(driver ,cookie):\n",
    "    try:\n",
    "        cookie = convertToCookie(cookie)\n",
    "        print(cookie)\n",
    "        if (cookie != None):\n",
    "            script = 'javascript:void(function(){ function setCookie(t) { var list = t.split(\"; \"); console.log(list); for (var i = list.length - 1; i >= 0; i--) { var cname = list[i].split(\"=\")[0]; var cvalue = list[i].split(\"=\")[1]; var d = new Date(); d.setTime(d.getTime() + (7*24*60*60*1000)); var expires = \";domain=.facebook.com;expires=\"+ d.toUTCString(); document.cookie = cname + \"=\" + cvalue + \"; \" + expires; } } function hex2a(hex) { var str = \"\"; for (var i = 0; i < hex.length; i += 2) { var v = parseInt(hex.substr(i, 2), 16); if (v) str += String.fromCharCode(v); } return str; } setCookie(\"' + cookie + '\"); location.href = \"https://mbasic.facebook.com\"; })();'\n",
    "            driver.execute_script(script)\n",
    "            sleep(5)\n",
    "    except:\n",
    "        print(\"Error login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "83aD8DMTx0S7"
   },
   "outputs": [],
   "source": [
    "def checkLiveClone(driver):\n",
    "    try:\n",
    "        driver.get(\"https://mbasic.facebook.com/\")\n",
    "        sleep(3)\n",
    "        driver.get(\"https://mbasic.facebook.com/\")\n",
    "        sleep(3)\n",
    "        elementLive = driver.find_elements(by=By.XPATH, value='//a[contains(@href, \"/messages/\")]')\n",
    "        if (len(elementLive) > 0):\n",
    "            print(\"Live\")\n",
    "            return True\n",
    "        return False\n",
    "    except:\n",
    "        print(\"Error Check Live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "F5qwxT1Vx1qH"
   },
   "outputs": [],
   "source": [
    "def loginFacebookByCookie(driver ,cookie):\n",
    "    try:\n",
    "        cookie = convertToCookie(cookie)\n",
    "        if (cookie != None):\n",
    "            script = 'javascript:void(function(){ function setCookie(t) { var list = t.split(\"; \"); console.log(list); for (var i = list.length - 1; i >= 0; i--) { var cname = list[i].split(\"=\")[0]; var cvalue = list[i].split(\"=\")[1]; var d = new Date(); d.setTime(d.getTime() + (7*24*60*60*1000)); var expires = \";domain=.facebook.com;expires=\"+ d.toUTCString(); document.cookie = cname + \"=\" + cvalue + \"; \" + expires; } } function hex2a(hex) { var str = \"\"; for (var i = 0; i < hex.length; i += 2) { var v = parseInt(hex.substr(i, 2), 16); if (v) str += String.fromCharCode(v); } return str; } setCookie(\"' + cookie + '\"); location.href = \"https://mbasic.facebook.com\"; })();'\n",
    "            driver.execute_script(script)\n",
    "            sleep(5)\n",
    "    except:\n",
    "        print(\"Error login\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UKkrCvv0x3TZ"
   },
   "outputs": [],
   "source": [
    "def checkLiveCookie(driver, cookie):\n",
    "    try:\n",
    "        driver.get('https://mbasic.facebook.com/')\n",
    "        sleep(3)\n",
    "        driver.get('https://mbasic.facebook.com/')\n",
    "        sleep(3)\n",
    "        loginFacebookByCookie(driver ,cookie)\n",
    "\n",
    "        return checkLiveClone(driver)\n",
    "    except:\n",
    "        print(\"Error Check Live\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "RQdmiWMhx5Dd"
   },
   "outputs": [],
   "source": [
    "def getCommentByPost(driver, postId, target = 500):\n",
    "    try:\n",
    "        driver.get(posts[postId])\n",
    "        try:\n",
    "            commentTags = driver.find_elements(by=By.XPATH, value='//div[contains(@data-sigil, \"comment-body\")]')\n",
    "            if (len(commentTags) < target):\n",
    "                nextButton = driver.find_elements(by=By.XPATH, value='//*[contains(@id,\"see_next\")]/a')\n",
    "                if(len(nextButton)==1):\n",
    "                    nextButton[0].click()\n",
    "                    sleep(3)\n",
    "                repliesButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@href,\"comment/replies/?ctoken=\")]')\n",
    "                while (len(repliesButtons) > 0):\n",
    "                    for repliesButton in repliesButtons:\n",
    "                        repliesButton.click()\n",
    "                        sleep(3)\n",
    "                    repliesButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@href,\"comment/replies/?ctoken=\")]')\n",
    "        except:\n",
    "            print(\"Error\")\n",
    "        commentTags = driver.find_elements(by=By.XPATH, value='//div[contains(@data-sigil, \"comment-body\")]')\n",
    "        if (len(commentTags)):\n",
    "            for comment in commentTags:\n",
    "                commentId = comment.get_attribute('data-commentid')\n",
    "                if(commentId and len(comments) < target):\n",
    "                    commentContent = comment.text\n",
    "                    innerLinks = comment.find_elements(by=By.TAG_NAME, value='a')\n",
    "                    if(len(innerLinks)):\n",
    "                        for innerLink in innerLinks:\n",
    "                            commentContent = commentContent.replace(innerLink.text, '')\n",
    "                    comments[commentId] = commentContent\n",
    "    except:\n",
    "        print(\"Error\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "DX0rk1bLx52R"
   },
   "outputs": [],
   "source": [
    "def getPostsByFanpage(driver, pageId, amount):\n",
    "    driver.get(\"https://touch.facebook.com/\" + pageId)\n",
    "    while len(posts) < amount:\n",
    "        sleep(3)\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight)\")\n",
    "        shareButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@href, \"/sharer.php\")]')\n",
    "        if (len(shareButtons)):\n",
    "            for shareButton  in shareButtons:\n",
    "                postId = shareButton.get_attribute('href').split('sid=')[1].split('&')[0]\n",
    "                commentButtons = driver.find_elements(by=By.XPATH, value='//a[contains(@data-click, \"click_comment_ufi\") and contains(@data-click, \"'+str(postId)+'\")]')\n",
    "                if (len(commentButtons) == 1 and len(posts) < amount):\n",
    "                    posts[postId] = commentButtons[0].get_attribute('href')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "s2ais30jx741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 15:21:20,180 INFO ====== WebDriver manager ======\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Current google-chrome version is 103.0.5060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 15:21:20,183 INFO Current google-chrome version is 103.0.5060\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Get LATEST chromedriver version for 103.0.5060 google-chrome\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 15:21:20,185 INFO Get LATEST chromedriver version for 103.0.5060 google-chrome\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[WDM] - Driver [C:\\Users\\Dang Khoa\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.53\\chromedriver.exe] found in cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 15:21:20,444 INFO Driver [C:\\Users\\Dang Khoa\\.wdm\\drivers\\chromedriver\\win32\\103.0.5060.53\\chromedriver.exe] found in cache\n",
      "Live\n"
     ]
    }
   ],
   "source": [
    "cookie = \"c_user=100082982745987; xs=47%3A3rDjZrheBR82cA%3A2%3A1657434894%3A-1%3A-1;\"\n",
    "driver = initDriver()\n",
    "isLive = checkLiveCookie(driver, cookie)\n",
    "if (isLive):\n",
    "    getPostsByFanpage(driver, 'Theanh28/photos/a.1509486855763896/6306054136107120', 1)\n",
    "    for postId in posts:\n",
    "        getCommentByPost(driver, postId, 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "lmhh2J1eyD3z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "bll2X3QFyE8f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "8K6HReI4yGU5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = comments.values()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "tpkid59lyHqQ"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-07-10 15:23:30,358 INFO NumExpr defaulting to 8 threads.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ ATM ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mình nhận nâng cấp YouTube Premium nha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Chỉ  &lt;3 áo đẹp giá rẻ ghé ngay &lt;3  &lt;3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>hyhy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>ờ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>đỉnh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ô nô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>chính m🤣</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>118 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment\n",
       "0    Công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...\n",
       "1    Chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ ATM ...\n",
       "2               Mình nhận nâng cấp YouTube Premium nha\n",
       "3     đệm vào chả vậy , ngực như cái chén lót thêm ...\n",
       "4                Chỉ  <3 áo đẹp giá rẻ ghé ngay <3  <3\n",
       "..                                                 ...\n",
       "113                                               hyhy\n",
       "114                                                  ờ\n",
       "115                                               đỉnh\n",
       "116                                               ô nô\n",
       "117                                           chính m🤣\n",
       "\n",
       "[118 rows x 1 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd   \n",
    "df = pd.DataFrame(data, columns=['comment'])\n",
    "df.to_csv('comments-predict.csv')\n",
    "df = pd.read_csv('comments-predict.csv')\n",
    "# Delete index column\n",
    "df.drop(df.columns[[0]], axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: emoji in c:\\programdata\\anaconda3\\lib\\site-packages (1.7.0)\n",
      "Requirement already satisfied: underthesea in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: underthesea-core==0.0.4_alpha.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (0.0.4a10)\n",
      "Requirement already satisfied: unidecode in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (1.2.0)\n",
      "Requirement already satisfied: Click>=6.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (8.0.4)\n",
      "Requirement already satisfied: requests in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (2.27.1)\n",
      "Requirement already satisfied: PyYAML in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (6.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (1.0.2)\n",
      "Requirement already satisfied: nltk in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (3.7)\n",
      "Requirement already satisfied: tqdm in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (4.64.0)\n",
      "Requirement already satisfied: python-crfsuite>=0.9.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (0.9.8)\n",
      "Requirement already satisfied: joblib in c:\\programdata\\anaconda3\\lib\\site-packages (from underthesea) (1.1.0)\n",
      "Requirement already satisfied: colorama in c:\\programdata\\anaconda3\\lib\\site-packages (from Click>=6.0->underthesea) (0.4.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from nltk->underthesea) (2022.3.15)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (3.3)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (2.0.4)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from requests->underthesea) (1.26.9)\n",
      "Requirement already satisfied: numpy>=1.14.6 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->underthesea) (1.21.5)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->underthesea) (1.7.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn->underthesea) (2.2.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install emoji\n",
    "!pip install underthesea"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import regex as re\n",
    "import emoji\n",
    "import string\n",
    "from underthesea import word_tokenize\n",
    "from underthesea import sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Dang Khoa\\AppData\\Local\\Temp\\ipykernel_13580\\1010956789.py:15: DeprecationWarning: 'emoji.get_emoji_regexp()' is deprecated and will be removed in version 2.0.0. If you want to remove emoji from a string, consider the method emoji.replace_emoji(str, replace='').\n",
      "To hide this warning, pin/downgrade the package to 'emoji~=1.6.3'\n",
      "  return emoji.get_emoji_regexp().sub(\"\", text)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "      <td>công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ atm ...</td>\n",
       "      <td>chạy chỉ tiêu thẻ atm ocb miễn phí kèm k hoa ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mình nhận nâng cấp youtube premium nha</td>\n",
       "      <td>nâng cấp youtube premium nha</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "      <td>đệm chả ngực chén lót vải vd bát úp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chỉ  &lt;3 áo đẹp giá rẻ ghé ngay &lt;3  &lt;3</td>\n",
       "      <td>áo đẹp giá rẻ ghé</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>m đấy</td>\n",
       "      <td>m đấy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>kì cục</td>\n",
       "      <td>kì cục</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>đỉnh</td>\n",
       "      <td>đỉnh</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ô nô</td>\n",
       "      <td>ô nô</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>chính m</td>\n",
       "      <td>m</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...   \n",
       "1    chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ atm ...   \n",
       "2               mình nhận nâng cấp youtube premium nha   \n",
       "3     đệm vào chả vậy , ngực như cái chén lót thêm ...   \n",
       "4                chỉ  <3 áo đẹp giá rẻ ghé ngay <3  <3   \n",
       "..                                                 ...   \n",
       "111                                             m đấy    \n",
       "112                                            kì cục    \n",
       "115                                               đỉnh   \n",
       "116                                               ô nô   \n",
       "117                                            chính m   \n",
       "\n",
       "                                               segment  \n",
       "0     công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...  \n",
       "1     chạy chỉ tiêu thẻ atm ocb miễn phí kèm k hoa ...  \n",
       "2                        nâng cấp youtube premium nha   \n",
       "3                 đệm chả ngực chén lót vải vd bát úp   \n",
       "4                                   áo đẹp giá rẻ ghé   \n",
       "..                                                 ...  \n",
       "111                                             m đấy   \n",
       "112                                            kì cục   \n",
       "115                                              đỉnh   \n",
       "116                                              ô nô   \n",
       "117                                                 m   \n",
       "\n",
       "[86 rows x 2 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Process data crawl before model\n",
    "\n",
    "# Basic preprocessing as lower string\n",
    "def pre_processing(text):\n",
    "    return text.str.lower()\n",
    "\n",
    "df['comment'] = pre_processing(df['comment'])\n",
    "\n",
    "# Delete NaN and empty row\n",
    "df = df[df.comment != '']\n",
    "df = df.dropna(subset=['comment'])\n",
    "df = df[df['comment'].apply(lambda comment: len(str(comment)) >= 5)]\n",
    "\n",
    "def remove_emoji(text):\n",
    "    return emoji.get_emoji_regexp().sub(\"\", text)\n",
    "\n",
    "df['comment'] = df['comment'].map(lambda comment: remove_emoji(comment))\n",
    "\n",
    "df['comment'] = df['comment'].map(lambda comment: comment.replace(string.punctuation,''))\n",
    "df['comment'] = df['comment'].map(lambda comment: comment.replace('_',' '))\n",
    "\n",
    "# Word segmentation\n",
    "df['segment'] = df['comment'].map(lambda comment: word_tokenize(comment))\n",
    "\n",
    "# Remove vietnamese stopwords - https://github.com/stopwords/vietnamese-stopwords\n",
    "\n",
    "# Read vietnamese stopwords file\n",
    "stopwords_df = pd.read_table('vietnamese-stopwords.txt')\n",
    "stopwords = stopwords_df.values.flatten()\n",
    "\n",
    "# Remove vietnamese stopwords function\n",
    "def remove_stopwords(segments):\n",
    "    return [item for item in segments if item not in stopwords]\n",
    "\n",
    "df['segment'] = df['segment'].map(lambda segments: remove_stopwords(segments))\n",
    "\n",
    "def process(text):\n",
    "    text = re.sub('&lt;/?.*?&gt;', ' &lt;&gt; ', str(text))\n",
    "    text = re.sub('(\\\\d|\\\\W)+', ' ', str(text))\n",
    "    return text\n",
    "\n",
    "df['segment'] = df['segment'].apply(lambda x: process(x))\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.preprocessing import MaxAbsScaler\n",
    "from sklearn.svm import LinearSVC\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...</td>\n",
       "      <td>['hôm nay', 'đi', 'châu đốc', 'ghé', 'quán', '...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đây hẳn hoi là sưởng bánh bao nên mua gần như ...</td>\n",
       "      <td>['hẳn hoi', 'sưởng', 'bánh bao', 'mua', 'giá b...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>không gian sang choảnh mà giá k hề sang tí nào...</td>\n",
       "      <td>['không gian', 'choảnh', 'giá', 'k', 'hề', 'tí...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhưng người ta xinh hơn c :))))</td>\n",
       "      <td>['người ta', 'xinh', 'c', ':))))']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...</td>\n",
       "      <td>['xem xét', 'kỹ', 'đi', 'mấy', 'thằng', 'đb']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109824</th>\n",
       "      <td>ý nghĩ tiêu cực.</td>\n",
       "      <td>['ý nghĩ', 'tiêu cực', '.']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109825</th>\n",
       "      <td>chết cụ lũ súc sinh chúng m</td>\n",
       "      <td>['chết', 'cụ', 'lũ', 'súc sinh', 'm']</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109826</th>\n",
       "      <td>thôi ông anh ơi, người bình thường chứ có phả...</td>\n",
       "      <td>[',', 'bình thường', 'thần thánh', 'đ', 'đòi',...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109827</th>\n",
       "      <td>tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...</td>\n",
       "      <td>['mạnh mẽ', '.', 'chúng em', 'đằng', 'sauuu', ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109828</th>\n",
       "      <td>thầy bán cho nó đúng k</td>\n",
       "      <td>['thầy', 'k']</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  \\\n",
       "0       hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...   \n",
       "1       đây hẳn hoi là sưởng bánh bao nên mua gần như ...   \n",
       "2       không gian sang choảnh mà giá k hề sang tí nào...   \n",
       "3                         nhưng người ta xinh hơn c :))))   \n",
       "4       hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...   \n",
       "...                                                   ...   \n",
       "109824                                   ý nghĩ tiêu cực.   \n",
       "109825                        chết cụ lũ súc sinh chúng m   \n",
       "109826   thôi ông anh ơi, người bình thường chứ có phả...   \n",
       "109827  tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...   \n",
       "109828                             thầy bán cho nó đúng k   \n",
       "\n",
       "                                                  segment emotion  \n",
       "0       ['hôm nay', 'đi', 'châu đốc', 'ghé', 'quán', '...     neg  \n",
       "1       ['hẳn hoi', 'sưởng', 'bánh bao', 'mua', 'giá b...     pos  \n",
       "2       ['không gian', 'choảnh', 'giá', 'k', 'hề', 'tí...     pos  \n",
       "3                      ['người ta', 'xinh', 'c', ':))))']     neu  \n",
       "4           ['xem xét', 'kỹ', 'đi', 'mấy', 'thằng', 'đb']     neu  \n",
       "...                                                   ...     ...  \n",
       "109824                        ['ý nghĩ', 'tiêu cực', '.']     neu  \n",
       "109825              ['chết', 'cụ', 'lũ', 'súc sinh', 'm']     neg  \n",
       "109826  [',', 'bình thường', 'thần thánh', 'đ', 'đòi',...     neu  \n",
       "109827  ['mạnh mẽ', '.', 'chúng em', 'đằng', 'sauuu', ...     pos  \n",
       "109828                                      ['thầy', 'k']     neu  \n",
       "\n",
       "[109829 rows x 3 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"comments.csv\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...</td>\n",
       "      <td>hôm nay đi châu đốc ghé quán hủ tiếu bình thư...</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>đây hẳn hoi là sưởng bánh bao nên mua gần như ...</td>\n",
       "      <td>hẳn hoi sưởng bánh bao mua giá buôn bánh hàng...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>không gian sang choảnh mà giá k hề sang tí nào...</td>\n",
       "      <td>không gian choảnh giá k hề tí hợp vs mấy hẹn ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nhưng người ta xinh hơn c :))))</td>\n",
       "      <td>người ta xinh c</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...</td>\n",
       "      <td>xem xét kỹ đi mấy thằng đb</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109824</th>\n",
       "      <td>ý nghĩ tiêu cực.</td>\n",
       "      <td>ý nghĩ tiêu cực</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109825</th>\n",
       "      <td>chết cụ lũ súc sinh chúng m</td>\n",
       "      <td>chết cụ lũ súc sinh m</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109826</th>\n",
       "      <td>thôi ông anh ơi, người bình thường chứ có phả...</td>\n",
       "      <td>bình thường thần thánh đ đòi học câu thi học ...</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109827</th>\n",
       "      <td>tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...</td>\n",
       "      <td>mạnh mẽ chúng em đằng sauuu i love sơn tùng m...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109828</th>\n",
       "      <td>thầy bán cho nó đúng k</td>\n",
       "      <td>thầy k</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>109829 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  comment  \\\n",
       "0       hôm nay đi châu đốc về ghé qua quán . hủ tiếu ...   \n",
       "1       đây hẳn hoi là sưởng bánh bao nên mua gần như ...   \n",
       "2       không gian sang choảnh mà giá k hề sang tí nào...   \n",
       "3                         nhưng người ta xinh hơn c :))))   \n",
       "4       hãy xem xét kỹ lại bản thân đi mấy thằng đb cơ...   \n",
       "...                                                   ...   \n",
       "109824                                   ý nghĩ tiêu cực.   \n",
       "109825                        chết cụ lũ súc sinh chúng m   \n",
       "109826   thôi ông anh ơi, người bình thường chứ có phả...   \n",
       "109827  tuổi mới phải thật mạnh mẽ anh nhé . hãy nhớ r...   \n",
       "109828                             thầy bán cho nó đúng k   \n",
       "\n",
       "                                                  segment emotion  \n",
       "0        hôm nay đi châu đốc ghé quán hủ tiếu bình thư...     neg  \n",
       "1        hẳn hoi sưởng bánh bao mua giá buôn bánh hàng...     pos  \n",
       "2        không gian choảnh giá k hề tí hợp vs mấy hẹn ...     pos  \n",
       "3                                        người ta xinh c      neu  \n",
       "4                             xem xét kỹ đi mấy thằng đb      neu  \n",
       "...                                                   ...     ...  \n",
       "109824                                   ý nghĩ tiêu cực      neu  \n",
       "109825                             chết cụ lũ súc sinh m      neg  \n",
       "109826   bình thường thần thánh đ đòi học câu thi học ...     neu  \n",
       "109827   mạnh mẽ chúng em đằng sauuu i love sơn tùng m...     pos  \n",
       "109828                                            thầy k      neu  \n",
       "\n",
       "[109829 rows x 3 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['segment'] = data['segment'].apply(lambda x: process(x))\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = data['segment']\n",
    "emotion = data['emotion']\n",
    "\n",
    "vectorizer = TfidfVectorizer(\n",
    "    binary=True, ngram_range=(1, 2),\n",
    "    sublinear_tf=True,\n",
    "    use_idf=True)\n",
    "\n",
    "X = vectorizer.fit_transform(segment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['vectorizer_file.sav']"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save vectorizer\n",
    "vectorizer_file = 'vectorizer_file.sav'\n",
    "joblib.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "# Load vectorizer\n",
    "loaded_vectorizer_file = joblib.load('vectorizer_file.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(87863, 700968) (87863,)\n",
      "(21966, 700968) (21966,)\n"
     ]
    }
   ],
   "source": [
    "#data test and data train \n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, emotion, test_size=0.2, random_state=0)\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model LinearSVC\n",
    "linear = LinearSVC(C=1, max_iter=1000)\n",
    "linear = linear.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['linear_model.sav']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linearModel = 'linear_model.sav'\n",
    "joblib.dump(linear, linearModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_linearModel = joblib.load('linear_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.75      0.70      0.73      8084\n",
      "         neu       0.70      0.82      0.75      7381\n",
      "         pos       0.80      0.71      0.75      6501\n",
      "\n",
      "    accuracy                           0.74     21966\n",
      "   macro avg       0.75      0.74      0.74     21966\n",
      "weighted avg       0.75      0.74      0.74     21966\n",
      "\n",
      "Accuracy score : 0.7431485022307202\n"
     ]
    }
   ],
   "source": [
    "#Test\n",
    "y_pred = loaded_linearModel.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(\"Accuracy score :\",accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'neu' 'neu' 'pos' 'neg' 'neu' 'pos' 'neu' 'neu' 'neu' 'neu'\n",
      " 'neu' 'neg' 'neg' 'neu' 'neu' 'pos' 'neu' 'neu' 'neu' 'neg' 'neg' 'neu'\n",
      " 'neg' 'neu' 'neu' 'pos' 'neu' 'neg' 'neg' 'pos' 'neu' 'neu' 'neg' 'neu'\n",
      " 'neg' 'neu' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neg' 'neu'\n",
      " 'neg' 'neu' 'neu' 'neu' 'neg' 'pos' 'neu' 'neu' 'neu' 'neg' 'neu' 'neu'\n",
      " 'neg' 'neg' 'neu' 'neu' 'neg' 'neu' 'neu' 'pos' 'neg' 'neu' 'neu' 'pos'\n",
      " 'neu' 'neu' 'neg' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'pos'\n",
      " 'neg' 'neu']\n"
     ]
    }
   ],
   "source": [
    "output = loaded_linearModel.predict(loaded_vectorizer_file.transform(df['segment']))\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "      <td>công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ atm ...</td>\n",
       "      <td>chạy chỉ tiêu thẻ atm ocb miễn phí kèm k hoa ...</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mình nhận nâng cấp youtube premium nha</td>\n",
       "      <td>nâng cấp youtube premium nha</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "      <td>đệm chả ngực chén lót vải vd bát úp</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chỉ  &lt;3 áo đẹp giá rẻ ghé ngay &lt;3  &lt;3</td>\n",
       "      <td>áo đẹp giá rẻ ghé</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>m đấy</td>\n",
       "      <td>m đấy</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>kì cục</td>\n",
       "      <td>kì cục</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>đỉnh</td>\n",
       "      <td>đỉnh</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ô nô</td>\n",
       "      <td>ô nô</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>chính m</td>\n",
       "      <td>m</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...   \n",
       "1    chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ atm ...   \n",
       "2               mình nhận nâng cấp youtube premium nha   \n",
       "3     đệm vào chả vậy , ngực như cái chén lót thêm ...   \n",
       "4                chỉ  <3 áo đẹp giá rẻ ghé ngay <3  <3   \n",
       "..                                                 ...   \n",
       "111                                             m đấy    \n",
       "112                                            kì cục    \n",
       "115                                               đỉnh   \n",
       "116                                               ô nô   \n",
       "117                                            chính m   \n",
       "\n",
       "                                               segment emotion  \n",
       "0     công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...     pos  \n",
       "1     chạy chỉ tiêu thẻ atm ocb miễn phí kèm k hoa ...     pos  \n",
       "2                        nâng cấp youtube premium nha      neu  \n",
       "3                 đệm chả ngực chén lót vải vd bát úp      neu  \n",
       "4                                   áo đẹp giá rẻ ghé      pos  \n",
       "..                                                 ...     ...  \n",
       "111                                             m đấy      neu  \n",
       "112                                            kì cục      neg  \n",
       "115                                              đỉnh      pos  \n",
       "116                                              ô nô      neg  \n",
       "117                                                 m      neu  \n",
       "\n",
       "[86 rows x 3 columns]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(2, \"emotion\", output)\n",
    "# df.drop(\"emotion\", axis=1, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#LogisticRegression model\n",
    "Logistic = LogisticRegression(max_iter=1000)\n",
    "Logistic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['logistic_model.sav']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logisticModel = 'logistic_model.sav'\n",
    "joblib.dump(Logistic, logisticModel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_logisticModel = joblib.load('logistic_model.sav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy LogisticRegression: 0.7473367932258945\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         neg       0.76      0.70      0.73      8084\n",
      "         neu       0.69      0.85      0.76      7381\n",
      "         pos       0.82      0.69      0.75      6501\n",
      "\n",
      "    accuracy                           0.75     21966\n",
      "   macro avg       0.76      0.75      0.75     21966\n",
      "weighted avg       0.76      0.75      0.75     21966\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_pred = loaded_logisticModel.predict(X_test)\n",
    "print(\"Accuracy LogisticRegression:\", accuracy_score(y_test,y_pred ))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pos' 'pos' 'neu' 'neu' 'pos' 'neg' 'neu' 'pos' 'neu' 'neu' 'neu' 'neu'\n",
      " 'neu' 'neg' 'neg' 'neu' 'neu' 'pos' 'neu' 'neu' 'neu' 'neg' 'neg' 'neu'\n",
      " 'neg' 'neg' 'neu' 'pos' 'neu' 'neg' 'neg' 'pos' 'neu' 'neu' 'neg' 'neu'\n",
      " 'neg' 'neu' 'neg' 'neu' 'neu' 'neu' 'neu' 'neu' 'neu' 'neg' 'neg' 'neu'\n",
      " 'neg' 'neu' 'neu' 'neg' 'neg' 'neg' 'neu' 'neu' 'neu' 'neg' 'neu' 'pos'\n",
      " 'neu' 'neg' 'neu' 'neu' 'neg' 'neu' 'neg' 'pos' 'neg' 'neu' 'neu' 'pos'\n",
      " 'neu' 'neu' 'neu' 'neg' 'neg' 'neu' 'neu' 'neg' 'neu' 'neu' 'neg' 'pos'\n",
      " 'neg' 'neu']\n"
     ]
    }
   ],
   "source": [
    "outputLogistic = loaded_logisticModel.predict(loaded_vectorizer_file.transform(df['segment']))\n",
    "print(outputLogistic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "      <th>segment</th>\n",
       "      <th>emotion</th>\n",
       "      <th>emotionLogistic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...</td>\n",
       "      <td>công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ atm ...</td>\n",
       "      <td>chạy chỉ tiêu thẻ atm ocb miễn phí kèm k hoa ...</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mình nhận nâng cấp youtube premium nha</td>\n",
       "      <td>nâng cấp youtube premium nha</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>đệm vào chả vậy , ngực như cái chén lót thêm ...</td>\n",
       "      <td>đệm chả ngực chén lót vải vd bát úp</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>chỉ  &lt;3 áo đẹp giá rẻ ghé ngay &lt;3  &lt;3</td>\n",
       "      <td>áo đẹp giá rẻ ghé</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>m đấy</td>\n",
       "      <td>m đấy</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>kì cục</td>\n",
       "      <td>kì cục</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>115</th>\n",
       "      <td>đỉnh</td>\n",
       "      <td>đỉnh</td>\n",
       "      <td>pos</td>\n",
       "      <td>pos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>ô nô</td>\n",
       "      <td>ô nô</td>\n",
       "      <td>neg</td>\n",
       "      <td>neg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>chính m</td>\n",
       "      <td>m</td>\n",
       "      <td>neu</td>\n",
       "      <td>neu</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>86 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               comment  \\\n",
       "0    công nhận, mấy bạn nữ ở nhà mặc đồ ngủ nhìn dễ...   \n",
       "1    chạy chỉ tiêu nên mình nhận hỗ trợ mở thẻ atm ...   \n",
       "2               mình nhận nâng cấp youtube premium nha   \n",
       "3     đệm vào chả vậy , ngực như cái chén lót thêm ...   \n",
       "4                chỉ  <3 áo đẹp giá rẻ ghé ngay <3  <3   \n",
       "..                                                 ...   \n",
       "111                                             m đấy    \n",
       "112                                            kì cục    \n",
       "115                                               đỉnh   \n",
       "116                                               ô nô   \n",
       "117                                            chính m   \n",
       "\n",
       "                                               segment emotion emotionLogistic  \n",
       "0     công nhận mấy nữ mặc đồ ngủ dễ thương kiểu te...     pos             pos  \n",
       "1     chạy chỉ tiêu thẻ atm ocb miễn phí kèm k hoa ...     pos             pos  \n",
       "2                        nâng cấp youtube premium nha      neu             neu  \n",
       "3                 đệm chả ngực chén lót vải vd bát úp      neu             neu  \n",
       "4                                   áo đẹp giá rẻ ghé      pos             pos  \n",
       "..                                                 ...     ...             ...  \n",
       "111                                             m đấy      neu             neu  \n",
       "112                                            kì cục      neg             neg  \n",
       "115                                              đỉnh      pos             pos  \n",
       "116                                              ô nô      neg             neg  \n",
       "117                                                 m      neu             neu  \n",
       "\n",
       "[86 rows x 4 columns]"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.insert(3, \"emotionLogistic\", output)\n",
    "# df.drop(\"emotion\", axis=1, inplace=True)\n",
    "df"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Sentiment.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
